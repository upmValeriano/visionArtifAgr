{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "objective-component",
   "metadata": {},
   "source": [
    "# Cadenas de Markov\n",
    "\n",
    "Una [Cadena de Markov](https://en.wikipedia.org/wiki/Markov_chain) es un proceso estocástico que cumple ciertas condiciones. \n",
    "\n",
    "Su nombre proviene del matemático ruso [Andrei Markov (1856-1922)](https://en.wikipedia.org/wiki/Andrey_Markov).\n",
    "\n",
    "## Definiciones\n",
    "\n",
    "### Proceso estocástico\n",
    "\n",
    "Un proceso estocástico es un conjunto de variables aleatorias\n",
    "\n",
    "$$\n",
    "\\{X_0,X_1,X_2,\\ldots\\}\n",
    "$$\n",
    "\n",
    "donde $X_t$ el estado en el tiempo $t$.\n",
    "\n",
    "Es decir, $X_t$ puede ser:\n",
    "\n",
    "* el tiempo que hace ({ref}`markov:4.1:ejemplo`)\n",
    "* la cantidad de dinero del apostador ({ref}`markov:4.1B:ruina`)\n",
    "* la posición de la pulga ({ref}`markov:4.1B:pulga`)\n",
    "* el resultado de tirar la moneda ({ref}`markov:4.1B:moneda`)\n",
    "* la clasificación del conductor por parte de la empresa de seguros ({ref}`markov:4.1B:conductores`)\n",
    "* el tipo de letra en un texto ({ref}`markov:4.1B:lenguaje`)\n",
    "* el estado del coloide ({ref}`markov:4.1B:coloides`)\n",
    "\n",
    "en el tiempo/posición $t$. El _estado_ del proceso estocástico en el tiempo $t$ es el _valor_ de $X_t$.\n",
    "\n",
    "+ Son modelos matemáticos __dinámicos__ y __estocásticos__.\n",
    "\n",
    "### Espacio de estados\n",
    "\n",
    "El espacio de estados $\\mathcal{X}$ es el conjunto de valores que puede tomar $X_t$. \n",
    "\n",
    "$$\n",
    "X_t\\in \\mathcal{X},\\quad \\forall t.\n",
    "$$\n",
    "\n",
    "Puede ser un conjunto infinito, pero nos limitaremos al caso en que\n",
    "\n",
    "$$\n",
    "|\\mathcal{X}|=r<\\infty.\n",
    "$$\n",
    "\n",
    "Es decir, veremos cadenas de Markov con un conjunto finito de estados\n",
    "\n",
    "$$\n",
    "\\mathcal{X}=\\{x_1,x_2,\\ldots,x_r\\}.\n",
    "$$\n",
    "\n",
    "::::{important}\n",
    "Cada uno de estos estados puede ocurrir con una cierta probabilidad y se cumple\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{r}\\mathbb{P}\\{X_t=x_i\\}=1.\n",
    "$$\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "### Trayectoria de un proceso estocástico\n",
    "\n",
    "Una trayectoria es un conjunto particular de valores de las variables aleatorias $X_t$. En el ejemplo de {ref}`markov:4.1B:pulga` una trayectoria puede ser\n",
    "\n",
    "$$\n",
    "1,2,3,2,4,...\n",
    "$$\n",
    "\n",
    "Si el proceso toma los valores $X_0=x_0,X_1=x_1,X_2=x_2,\\ldots$ decimos que la trayectoria es\n",
    "\n",
    "$$\n",
    "x_0,x_1,x_2,\\ldots\n",
    "$$\n",
    "\n",
    "::::{note}\n",
    "Se suele llamar _path_ a la trayectoria.\n",
    "::::\n",
    "\n",
    "### Propiedad Markoviana\n",
    "\n",
    "Las cadenas de Markov han de cumplir la [__propiedad Markoviana__](https://en.wikipedia.org/wiki/Markov_property) que viene a decir que el proceso no tiene _memoria_.\n",
    "\n",
    "El estado $X_{t+1}$ depende únicamente del estado $X_t$.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_{t+1}=x|X_t=x_t,X_{t-1}=x_{t-1},\\ldots,X_0=x_0\\}=\n",
    "\\mathbb{P}\\{X_{t+1}=x|X_t=x_t\\},\n",
    "$$\n",
    "\n",
    "para todo $t,x,x_{t},x_{t-1},\\ldots,x_0$.\n",
    "\n",
    "::::{note}\n",
    "Un proceso estocástico que cumpla la propiedad Markoviana es una __cadena de Markov__.\n",
    "::::\n",
    "\n",
    "\n",
    "\n",
    "### Distribución de $X_t$\n",
    "\n",
    "Dada una cadena de Markov $\\{X_0,X_1,X_2,\\ldots\\}$ con espacio de estados $\\mathcal{X}=\\{x_1,x_2,\\ldots,x_r\\}$, cada una de las $X_t$ es una [variable aleatoria](https://en.wikipedia.org/wiki/Random_variable), por tanto tendrá una distribución de probabilidad (discreta).\n",
    "\n",
    "Podemos escribir esta distribución de probabilidad de un modo vectorial.\n",
    "\n",
    "Consideramos $X_0$. Denotamos su distribución de probabilidad como\n",
    "\n",
    "$$\n",
    "\\pi^{(0)}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\pi_1^0\n",
    "\\\\\n",
    "\\pi_2^0\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\ \n",
    "\\pi_r^0\n",
    "\\end{pmatrix}^T\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\mathbb{P}\\{X_0=x_1\\} \\\\\n",
    "\\mathbb{P}\\{X_0=x_2\\} \\\\\n",
    "\\vdots\\\\\n",
    "\\mathbb{P}\\{X_0=x_r\\}\n",
    "\\end{pmatrix}^T.\n",
    "$$\n",
    "\n",
    "Escribimos\n",
    "\n",
    "$$\n",
    "X_0\\sim \\pi^{(0)}.\n",
    "$$\n",
    "\n",
    "En el ejemplo {ref}`markov:4.1B:pulga` esto se corresponde con la elección aleatoria de la pulga acerca de en qué vértice empezar a saltar en tiempo 0:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\text{la pulga empieza en el vértice $i$})=\\pi_i.\n",
    "$$\n",
    "\n",
    "\n",
    "### Probabilidades de transición\n",
    "\n",
    "+ Consideramos una cadena de Markov con $r$ estados. Sea la probabilidad \n",
    "\n",
    "$$\n",
    "{\\color{red}p_{ij}}=\n",
    "\\mathbb{P}\\{\n",
    "X_t=x_j|X_{t-1}=x_i\\}\\qquad i,j=1,\\ldots,r\n",
    "$$\n",
    "\n",
    "de que el sistema __pase del estado $i$ al estado $j$__ en la iteración $t$.\n",
    "\n",
    "::::{note}\n",
    "Consideraremos cadenas de Markov homogéneas en el tiempo. Las probabilidades de transición __no__ dependen del tiempo:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_{n+1}=x_j|X_n=x_i\\}=\n",
    "\\mathbb{P}\\{X_{1}=x_j|X_0=x_i\\}\\qquad \\forall n.\n",
    "$$\n",
    "::::\n",
    "\n",
    "\n",
    "### Matriz de transición\n",
    "\n",
    "Llamamos matriz de transiciones de la cadena de Markov a la matriz $r\\times r$:\n",
    "\n",
    "$$\n",
    "P=(p_{ij}).\n",
    "$$\n",
    "\n",
    "+ Son matrices __cuadradas__. Las filas representan el estado de entrada y las columnas el de salida.\n",
    "\n",
    "+ $0\\leq p_{ij}\\leq 1$ (las entradas de la matriz son __probabilidades__).\n",
    "\n",
    "+ Las $\\color{red}{\\text{filas}}$ suman 1:\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^rp_{ij}=1,\\quad i=1,\\ldots,r.\n",
    "$$\n",
    "\n",
    "::::{note}\n",
    "Toda matriz que verifique estas propiedades se llama [__matriz estocástica__](https://en.wikipedia.org/wiki/Stochastic_matrix) (por filas).\n",
    "::::\n",
    "\n",
    "\n",
    "\n",
    "### Probabilidades de transición a $n$ pasos\n",
    "\n",
    "Dada una cadena de Markov con matriz de transición $P$ __y condición inicial $X_0=x_i$__, ya sabemos cómo calcular la distribución de probabilidad de $X_1$. En nuestra notación\n",
    "\n",
    "$$\n",
    "X_1\\sim \\pi^{(1)}=\n",
    "\\begin{pmatrix}\n",
    "\\mathbb{P}\\{X_1=x_1\\}\\\\\n",
    "\\mathbb{P}\\{X_1=x_2\\}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathbb{P}\\{X_1=x_r\\}\n",
    "\\end{pmatrix}^T\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "p_{i1}\\\\\n",
    "p_{i2}\\\\\n",
    "\\vdots\\\\\n",
    "p_{ir}\n",
    "\\end{pmatrix}^T.\n",
    "$$\n",
    "\n",
    "Es natural preguntarse cuál será la distribución en tiempos posteriores. Estamos interesados en conocer las __probabilidades de transición a $n$ pasos__, $P^{(n)}$, definidas por\n",
    "\n",
    "$$\n",
    "P_{ij}^{(n)}=\\mathbb{P}\\{X_{n}=x_j|X_0=x_i\\}.\n",
    "$$\n",
    "\n",
    "Para $n=2$ tenemos:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{P}\\{X_2=x_j|X_0=x_i\\}&=\n",
    "\\sum_{k=1}^r \\mathbb{P}\\{X_2=x_j|X_1=x_k,X_0=x_i\\} \\mathbb{P}\\{X_1=x_k|X_0=x_i\\}\n",
    "\\tag{Ley de Probabilidad Total}\\\\\n",
    " =&\\sum_{k=1}^r \\mathbb{P}\\{X_2=x_j|X_1=x_k\\} \\mathbb{P}\\{X_1=x_k|X_0=x_i\\}\n",
    "\\tag{Propiedad Markoviana}\\\\\n",
    "=&\\sum_{k=1}^rP_{kj}P_{ik}\n",
    "\\tag{Matriz de transición}\\\\\n",
    "=&\\sum_{k=1}^rP_{ik}P_{kj}\n",
    "\\tag{Reordenando}\\\\\n",
    "=&(P^2)_{ij}\n",
    "\\end{align*}\n",
    "\n",
    "La matriz de transición a 2 pasos $P^{(2)}=P^2$.\n",
    "\n",
    "Tenemos el siguiente:\n",
    "\n",
    "````{prf:theorem}\n",
    "Sea $\\{X_0,X_1,\\ldots\\}$ una cadena de Markov con matriz de transición $P$. Las probabilidades de transición a $n$ pasos son $P^{(n)}=P^n$, es decir\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_n=x_j|X_0=x_i\\}=(P^n)_{ij}.\n",
    "$$\n",
    "````\n",
    "\n",
    "::::{note}\n",
    "Usaremos la notación $(P^n)_{ij}=P_{ij}^n$.\n",
    "::::\n",
    "\n",
    "\n",
    "\n",
    "```{warning} \n",
    "Lo anterior __no__ es igual a $(P_{ij})^n$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-mason",
   "metadata": {},
   "source": [
    "## Dinámica\n",
    "\n",
    "Supongamos que conocemos el vector de probabilidades inicial $\\mathbf{\\pi}^{(0)}$.\n",
    "¿Cómo determinamos los siguientes vectores de probabilidad en los\n",
    "siguientes pasos temporales?\n",
    "\n",
    "Estamos interesados en conocer la distribución de $X_n$, que almacenamos en $\\pi^{(n)}$, es decir\n",
    "\n",
    "$$\n",
    "\\pi_i^{(n)}=\\mathbb{P}\\{X_n=x_i\\}.\n",
    "$$\n",
    "\n",
    "Calculamos $\\pi^{(n+1)}$ asumiendo que conocemos $\\pi^{(n)}$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\pi_j^{(n+1)}&=\\sum_{i} \\mathbb{P}\\{X_{n+1}=x_j|X_{n}=x_i\\} \\mathbb{P}\\{X_n=x_i\\}\\tag{Probabilidad total}\\\\\n",
    "&=\\sum_{i}P_{ij}\\pi_i^{(n)}\\tag{definición de $\\pi^{(n)}$.}\n",
    "\\end{align*}\n",
    "\n",
    "Se tiene el siguiente:\n",
    "\n",
    "\n",
    "````{prf:theorem}\n",
    "\n",
    "Si $P$ es la matriz de transiciones de una cadena de Markov y $\\pi^{(n)}$ es\n",
    "el vector de probabilidades en la $n$-ésima observación, entonces\n",
    "\n",
    "$$\n",
    "\\pi^{(n+1)} = \\pi^{(n)} P.$$\n",
    "\n",
    "Por tanto: \n",
    "\n",
    "$$\\pi^{(n)} = \\pi^{(0)} P^n ,\n",
    "$$\n",
    "\n",
    "siendo $\\pi^{(0)}$ el vector de probabilidades inicial.\n",
    "\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-thumb",
   "metadata": {},
   "source": [
    "## Probabilidad de una secuencia de estados\n",
    "\n",
    "Nos interesamos ahora por la __probabilidad de observar una\n",
    "secuencia__ de longitud $n$, $seq = \\{x_1 , x_2 , \\ldots , x_n \\}$:\n",
    "\n",
    "$$\\mathbb{P}\\{seq\\}=\n",
    "\\mathbb{P}\\{\n",
    "X_n=x_n,X_{n-1}=x_{n-1},\\ldots,X_1=x_1\\}\n",
    "$$\n",
    "\n",
    "que podemos reescribir como:\n",
    "\n",
    "$$\\mathbb{P}\\{seq\\}=\n",
    "\\mathbb{P}\\{\n",
    "X_n=x_n|X_{n-1}=x_{n-1},\\ldots,X_1=x_1\\}\n",
    "\\mathbb{P}\\{\n",
    "X_{n-1}=x_{n-1}|X_{n-2}=x_{n-2},\\ldots,X_1=x_1\\}\\ldots\\mathbb{P}\\{X_1=x_1\\}\n",
    "$$\n",
    "\n",
    "Gracias a la propiedad Markoviana, que dice que la probabilidad de observar $X_t$ solamente depende de la probabilidad de $X_{t-1}$, la anterior expresión se simplifica:\n",
    "\n",
    "$$\\mathbb{P}\\{seq\\}=\\mathbb{P}\\{X_n=x_n|X_{n-1}=x_{n-1}\\}\n",
    "\\mathbb{P}\\{X_{n-1}=x_{n-1}|X_{n-2}=x_{n-2}\\}\n",
    "\\ldots\\mathbb{P}\\{X_2=x_2|X_1=x_1\\}\\mathbb{P}\\{X_1=x_1\\}\n",
    "$$\n",
    "\n",
    "que simplificamos como:\n",
    "\n",
    "$$\\mathbb{P}\\{seq\\}=\n",
    "\\mathbb{P}\\{X_1=x_1\\}\n",
    "\\prod_{t=2}^{n}\\mathbb{P}\\{X_t=x_t|X_{t-1}=x_{t-1}\\}\n",
    "$$\n",
    "\n",
    "::::{important}\n",
    "Conocido el __vector de probabilidades iniciales__, $\\pi^{(0)}$ , y la __matriz de\n",
    "transiciones__ $P$, podemos calcular la probabilidad de observar una\n",
    "secuencia cualquiera (numéricamente es mejor calcular $\\log \\mathbb{P}\\{seq\\}$).\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-president",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNN - Ejercicio splicing para Entrega\n",
    "\n",
    "__Ejercicio de redes neuronales para estudiar de secuencias de RNA__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las herramientas de sk-learn se reproducirá la red diseñada para el problema de RNA splicing por los autores:\n",
    "\n",
    "M. O. Noordewier and G. G. Towell and J. W. Shavlik Training Knowledge-Based Neural Networks to Recognize Genes in DNA Sequences. Advances in Neural Information Processing Systems, vol. 3, Morgan Kaufmann (1991)\n",
    "\n",
    "<img src=\"images/kbann-splicing.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos a partir de CSV\n",
    "\n",
    "Como el archivo no incluye los nombres de las columnas se asigna el nombre a partir de una lista con el parámetro __names__ de __read_csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Instance</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EI</td>\n",
       "      <td>ATRINS-DONOR-521</td>\n",
       "      <td>CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EI</td>\n",
       "      <td>ATRINS-DONOR-905</td>\n",
       "      <td>AGACCCGCCGGGAGGCGGAGGACCTGCAGGGTGAGCCCCACCGCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EI</td>\n",
       "      <td>BABAPOE-DONOR-30</td>\n",
       "      <td>GAGGTGAAGGACGTCCTTCCCCAGGAGCCGGTGAGAAGCGCAGTCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EI</td>\n",
       "      <td>BABAPOE-DONOR-867</td>\n",
       "      <td>GGGCTGCGTTGCTGGTCACATTCCTGGCAGGTATGGGGCGGGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EI</td>\n",
       "      <td>BABAPOE-DONOR-2817</td>\n",
       "      <td>GCTCAGCCCCCAGGTCACCCAGGAACTGACGTGAGTGTCCCCATCC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class            Instance                                           Sequence\n",
       "0    EI    ATRINS-DONOR-521  CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCC...\n",
       "1    EI    ATRINS-DONOR-905  AGACCCGCCGGGAGGCGGAGGACCTGCAGGGTGAGCCCCACCGCCC...\n",
       "2    EI    BABAPOE-DONOR-30  GAGGTGAAGGACGTCCTTCCCCAGGAGCCGGTGAGAAGCGCAGTCG...\n",
       "3    EI   BABAPOE-DONOR-867  GGGCTGCGTTGCTGGTCACATTCCTGGCAGGTATGGGGCGGGGCTT...\n",
       "4    EI  BABAPOE-DONOR-2817  GCTCAGCCCCCAGGTCACCCAGGAACTGACGTGAGTGTCCCCATCC..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las secuencias tienen 60 pares de bases. La primera columna (__Class__) indica la clase a la que pertenece la secuencia: EI para las que proporcionan un salto exon-intrón (donores); IE para las secuencias que contienen una frontera intron-exón (aceptores); N para aquellas secuencias que no son ni EI ni IE. \n",
    "\n",
    "La segunda columna (__Instance__) es una etiqueta para cada una de las instancias (filas), y la tercera columna da la __secuencia__ correspondiente en terminos del alfabeto A, T, C y G."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproceso de las secuencias\n",
    "\n",
    "Algunas de las secuencias tienen ambiguedad en determinadas posiciones, de forma que incluyen las letras D, N, S o R de acuerdo con la siguiente tabla:\n",
    "\n",
    "| Letra | Significado |\n",
    "| ----- | ------- |\n",
    "| D | A o G o T |\n",
    "| N | A o G o T o C |\n",
    "| S | C o G |\n",
    "| R | A o G |\n",
    "\n",
    "Estos caracteres ambiguos aparecen en muy pocas instancias, así que se van a eliminar de los datos para simplificar el analisis. Primero se realiza un proceso de filtrado para saber cuantas secuencias quedan:\n",
    "\n",
    "__Se borran las secuencias ambiguas como ya se vió en el ejercicio anterior__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero se prepara la matriz X de los conjuntos de entranamiento y pruebas\n",
    "\n",
    "Se separa la secuencia en 60 campos de un caracter identificando la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222 60 2222\n",
      "953 60 953\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2222, 60), (953, 60))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efectuar el entrenamiento con el Perceptron multicapa (Multilayer perceptron - MLP)\n",
    "\n",
    "La librería __sk-learn__ en el módulo __neural_network__ implementa el perceptron multicapa en la clas __MLPClassifier__.\n",
    "\n",
    "Los parámetros del constructor de la clase __MLPClassifier__ son:\n",
    "- __hidden_layer_sizes__ : Este parámetro permite establecer el número de capas y el número de nodos que se desean tener en el clasificador de redes neuronales. Cada elemento de la tupla representa el número de nodos en la i-ésima posición, donde i es el índice de la tupla. Por tanto, la longitud de la tupla denota el número total de capas ocultas en la red.\n",
    "- __max_iter__ : número de épocas de entrenamiento.\n",
    "- __activation__ : función de activación de las capas ocultas.\n",
    "- __solver__ : algoritmo empleado en la optimización de los pesos de los nodos.\n",
    "- __random_state__ : establece una semilla para reproducir los mismos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X_train60[0]), np.unique(y_train), len(X_train60), len(y_train), len(X_test60), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos objeto con el constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer_z\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(60, 240, 43, 3), max_iter=3000,\n",
       "              random_state=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Entrenamiento de la red\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Se presenta la exactitud del conjunto de entrenamiento y pruebas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica con Pytorch. Opcionalmente con Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La práctica consistirá en realizar, al menos, una época de entrenamiento al conjunto de fotos de plantas con diversas patologias __PlantVillage__.\n",
    "\n",
    "Se accederá al cuaderno que aparece en Moodle que se puede modificar reduciendo el tamaño de imagen para agilizar el proceso. El entrenamiento hay que realizarlo con el conjunto de 70.000 fotos que aparecen en la carpeta __train__ y la validación o bien con el conjunto de test __val__ de 10.000 fotos o con el conjunto abreviado de 380 fotos. Al dataset PlantVillage se accede en la siguiente carpeta compartida de Google Drive:\n",
    "\n",
    "\n",
    "<a href=\"PlantVillage en Google Drive\">https://drive.google.com/drive/folders/1bSkEQm7bAOzI09kbz0ltLnJjrerEmknG?usp=sharing</a>\n",
    "\n",
    "Hay dos formas de trabajar:\n",
    "\n",
    "* Se puede descargar de Google Drive la __carpeta en local__ y efectuar el proceso.\n",
    "* Probar en Google Colab usando la carpeta, como compartida y creando un acceso directo en Drive. En Google Colab se puede activar el entorno de ejecución GPU.\n",
    "\n",
    "Conseguida la ejecución dar unos __resultados de rendimiento__ con las opciones que se hayan probado. Utilizar una libreria que obtenga el tiempo de proceso y se pueda calcular el coste en minutos de la ejecución. El alumno entregará un cuaderno con la evidencia o un enlace a su Google Drive con la ejecución en Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_googlecolab.png\" width=\"150px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://githubtocolab.com/upmValeriano/notebook/blob/main/AA/05_07C_RRNN_Convoluciones_PlantVillage.ipynb\" target=\"_blank\">\n",
    "<FONT SIZE=4>Abrir Cuaderno PlantVillage en Google Colab</font></a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

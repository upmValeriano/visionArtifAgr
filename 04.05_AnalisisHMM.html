
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Análisis de HMM &#8212; Introducción al Aprendizaje Automático</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04.05_AnalisisHMM';</script>
    <link rel="icon" href="_static/EscUpm.jpg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Práctica 1: cadenas de Markov como Modelos de Secuencias" href="04.06_CadenasMarkov.html" />
    <link rel="prev" title="Modelos de Markov Ocultos" href="04.04_ModelosMarkovOcultos.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="introAA.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/LOGOTIPOcolorPNG.png" class="logo__image only-light" alt="Introducción al Aprendizaje Automático - Home"/>
    <script>document.write(`<img src="_static/LOGOTIPOcolorPNG.png" class="logo__image only-dark" alt="Introducción al Aprendizaje Automático - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">
 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="introAA.html">
                    Bienvenida
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="01_IntroduccionIntro.html">Presentación</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="01.1_Introduccion.html">Introducción al Aprendizaje Automático</a></li>
<li class="toctree-l2"><a class="reference internal" href="01.2_InstalacionJupyter.html">Instalación de Python y Cuadernos Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="01.3_EjemplosdePythonparaaprenderaprogramar.html">Repaso de programación en Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="01.4_InstalacionLibrerias.html">Instalación de Librerías</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="02_ClasificacionIntro.html">Clasificación</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="02.1_MetodosdeClasificacion-Naive-Bayes.html">Clasificación naive-Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.2_MetodosdeClasificacion-Naive-Bayes-RNA-SPLICING.html">Clasificación naive-Bayes de secuencias de ADN</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.3_MetodosdeClasificacion-Ratioseindicadores.html">Ratios e indicadores</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.4_MetodosdeClasificacion-ArbolesdeDecision.html">Árboles de Decisión</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.6_Clasificacion-Ejercicioparaentregarsobrevariedadevinicolas.html">Ejercicio sobre variedades vínicolas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="03_ClusteringIntro.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="03.0_ClusteringUtilidades.html">Utilidad para Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.1_Clustering-K-Means.html">Aprendizaje no supervisado. Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.2_Clustering-Jerarquicosydensidad.html">Clustering Jerárquico, Densidad y Mean-Shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.3_Clustering_Analisis_Microarrays.html">Clustering. Análisis de microarrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.4_ClusteringEntregaDiabetesIndiosPima.html">Ejercicio de Clustering con fichero de diabetes (indios Pima)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="04_CadenasMarkovIntro.html">Cadenas de Markov</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="04.00_ObjetivoAnalisisSecuencias.html">Análisis de Secuencias: Objetivo</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.01_CadenasMarkovIntroduccion.html">Ejemplo inicial de cadena de Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.01B_CadenasMarkovEjemplos.html">Otros ejemplos</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.02_CadenasMarkovResultados.html">Cadenas de Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.02B_CadenasMarkovAsintotico.html">Comportamiento asintótico</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.03_CadenasMarkovModelosSecuencias.html">Cadenas de Markov como modelos de secuencias</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.04_ModelosMarkovOcultos.html">Modelos de Markov Ocultos</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Análisis de HMM</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.06_CadenasMarkov.html">Práctica 1: cadenas de Markov como Modelos de Secuencias</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.07_CadenasDeMarkovOcultas.html">Práctica 2: predicción de estructuras secundarias en proteínas</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.08_MarkovExtra.html">Entrega: secuencia más probable en una cadena de Markov.</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="05_rnnIntro.html">Redes Neuronales</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="05.0_Redes_Neuronales_Utilidades.html">Redes Neuronales Utilidades</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.1_RedesNeuronalesIntroduccion.html">Redes Neuronales Introducción</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.2_RedesNeuronales-ModeloBicapa.html">Redes Neuronales - Modelo Bicapa</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.3_RedesNeuronales-ModeloMultiCapa.html">Redes Neuronales - Modelo MultiCapa</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.4_RRNN-Ejercicio%20Wine.html">RRNN - Ejercicio Wine</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.5_RRNN_Analisis_Microarrays.html">RRNN Análisis de microarrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.6_RRNN-EjerciciosplicingparaEntrega.html">RNNN - Ejercicio splicing para Entrega</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.07A_RRNN_Convoluciones_CIFAR_10.html">Redes Neuronales Convoluciones con arquitectura Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.07B_RRNN_Convoluciones_Maqueta.html">Maqueta de red neuronal convolucional</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.08RRNN_AlphaFold_GeometriaProteinas_Pytorch.html">AlphaFold. Geometria de las Proteinas</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.09RRNN_PointNet_con_Pytorch.html">Identificación 3D con PointNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.10RRNN_Segmentar_Imagenes_2D.html">Segmentación de imágenes 2D con redes completamente convolucionales</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.11RRNN_Segmentar_Imagenes_2D_cityscapes.html">Segmentación de imágenes 2D con redes completamente convolucionales (conjunto Cityscapes)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.12RRNN_Segmentacion_Instancias_2D_MaskRCNN.html">Segmentación de instancias 2D con Mask R-CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.13RRNN_Implementar_una_red_LSTM_con_pytorch_series_temporales.html">Implementar una Red Neuronal para una Serie Temporal (LSTM)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="06_mapasAutoorganizativosIntro.html">Mapas Autoorganizativos</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="06.01_SOM_VisualizarDatos.html">Motivación: visualizar datos multidimensionales</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.02_SOM_MapaAutoorganizativo.html">Mapas autoorganizativos</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.03_SOM_Algoritmo.html">El Algoritmo <em>SOM</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="06.04_SOM_AplicacionesBiotecnologia.html">Aplicaciones en biotecnología</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.05_SOM_EjemploPoblacionIrlanda.html">Ejemplo con Datos demográficos</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.06_SOM_EjemploColoresRGB.html">Ejemplo con Colores RGB</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.07_SOM_Practica1_Python_v5.html">Práctica 1: Algoritmo SOM de Kohonen en una dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.08_SOM_Practica2_RegionesVinicolas_Python.html">Práctica 2. <em>Clustering</em> de regiones vinícolas</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.09_SOM_Practica3_SOMClasificador_Python.html">Práctica 2. Continuación</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.10_SOM_Practica4_TareaExtra.html">Entrega</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="07_algoritmosGeneticosIntro.html">Algoritmos Genéticos</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="07.01_GA1.html">Algoritmos Genéticos</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.02_GA2.html">Los algoritmos genéticos</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.03_GA3.html">El Algoritmo Genético</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.04_GA4_Robbie.html">Robbie el Robot Recogebasura</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.05_GA5_Practica1.html">Práctica 1: Pasos elementales del GA</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.06_GA6_Practica2_OptimizarFuncion.html">Práctica 2: Optimizar función</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.07_GA7_Practica3_TSP.html">Práctica 3: <em>Travelling Salesman</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="07.08_GA8_Practica_Extra.html">Entrega: <em>Animula Vagula Blandula</em></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Bibliografia.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/04.05_AnalisisHMM.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Análisis de HMM</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje">4.5.1 Aprendizaje</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-1-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">Caso 1: conocemos las secuencias de estados asociadas a los símbolos</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-2-no-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">Caso 2: no conocemos las secuencias de estados asociadas a los símbolos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion">4.5.2 Evaluación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#descodificacion">4.5.3 Descodificación</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-de-viterbi">Algoritmo de Viterbi</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="analisis-de-hmm">
<h1>Análisis de HMM<a class="headerlink" href="#analisis-de-hmm" title="Link to this heading">#</a></h1>
<p>Tenemos tres fases:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#content-markov-hmm-aprendizaje"><span class="std std-ref"><strong>Aprendizaje</strong></span></a>: dada una lista de secuencias de sı́mbolos, ¿podemos <strong>aprender</strong> los parámetros <span class="math notranslate nohighlight">\((\pi^{(0)} , P, E )\)</span> de un HMM? <strong>Algoritmo de Baum-Welch</strong>.</p></li>
<li><p><a class="reference internal" href="#content-markov-hmm-evaluacion"><span class="std std-ref"><strong>Evaluación</strong></span></a>: una vez que el modelo está ajustado, ¿cuál es la verosimilitud de una secuencia dada? <strong>Algoritmo “forward”</strong>.</p></li>
<li><p><a class="reference internal" href="#content-markov-hmm-descodificacion"><span class="std std-ref"><strong>Descodificación</strong></span></a>: una vez que el modelo está ajustado, ¿cuál es el la secuencia de estados <strong>más probable</strong> para generar de una secuencia de sı́mbolos dada? <strong>Algoritmo de Viterbi</strong>.</p></li>
</ol>
<section id="aprendizaje">
<span id="content-markov-hmm-aprendizaje"></span><h2>4.5.1 Aprendizaje<a class="headerlink" href="#aprendizaje" title="Link to this heading">#</a></h2>
<p>Dos casos:</p>
<ol class="arabic simple">
<li><p>Si conocemos las secuencias de estados asociadas a cada secuencia de sı́mbolos</p></li>
<li><p>Si no los conocemos</p></li>
</ol>
<section id="caso-1-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">
<h3>Caso 1: conocemos las secuencias de estados asociadas a los símbolos<a class="headerlink" href="#caso-1-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos" title="Link to this heading">#</a></h3>
<p>En proteı́nas, esto equivale a conocer la estructura secundaria de cada secuencia de aminoácidos.</p>
<ul class="simple">
<li><p>La verosimilitud de que una secuencia de estados <span class="math notranslate nohighlight">\(\mathcal{est}=\{x_1,\ldots,x_n\}\)</span> genere una secuencia de símbolos <span class="math notranslate nohighlight">\(\mathcal{sim}=\{s_1,\ldots,s_n\}\)</span> es:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\{\mathcal{est},\mathcal{sim}\}=
\mathbb{P}\{X_1=x_1\}\mathbb{P}\{S_1=s_1|X_1=x_1\}\times
\prod_{t=2}^{n}\mathbb{P}\{X_t=x_t|X_{t-1}=x_{t-1}\}\mathbb{P}\{S_t=s_t|X_t=x_t\}
\]</div>
<ul class="simple">
<li><p>Entonces el método de <strong>máxima verosimilitud</strong> permite estimar los parámetros como frecuencias relativas en el conjunto de entrenamiento.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>En el <strong>conjunto de entrenamiento</strong></p>
</div>
<ul class="simple">
<li><p>Probabilidades de transición:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p_{ij}=\frac{\text{número de transiciones desde $X=x_i$ hasta $X=x_j$}}{\text{número de transiciones que parten de $X=x_i$}}
\]</div>
<ul class="simple">
<li><p>Probabilidades de emisión:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
e_{ij}=
\frac{\text{número de veces que el estado $X=x_i$ emite el símbolo $S=s_j$}}{\text{número de veces que el estado es $X=x_i$}}
\]</div>
<ul class="simple">
<li><p>Vector inicial:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\pi^{(0)}_{i}=
\frac{\text{número de veces que el estado inicial es $X=x_i$}}
{\text{número total de instancias}}
\]</div>
</section>
<section id="caso-2-no-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">
<h3>Caso 2: no conocemos las secuencias de estados asociadas a los símbolos<a class="headerlink" href="#caso-2-no-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos" title="Link to this heading">#</a></h3>
<p>En proteı́nas, esto equivale a conocer solamente las secuencias de aminoácidos.</p>
<ul class="simple">
<li><p>Este es el caso más frecuente en la práctica.</p></li>
<li><p>En este caso se puede aplicar el <strong>algoritmo de Baum-Welch</strong>, que estima también las probabilidades de transición aunque no conozcamos las secuencias de estados.</p></li>
</ul>
</section>
</section>
<section id="evaluacion">
<span id="content-markov-hmm-evaluacion"></span><h2>4.5.2 Evaluación<a class="headerlink" href="#evaluacion" title="Link to this heading">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>¡Tras la fase de aprendizaje!</p>
</div>
<p>Dada una secuencia de <strong>sı́mbolos</strong> (aminoácidos), ¿puedo calcular la probabilidad de observarla de acuerdo con el HMM?</p>
<ul class="simple">
<li><p>Equivale a calcular la probabilidad marginal</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\{\mathcal{sim}\}=
\sum_{\{x_1,\ldots,x_n\}}
\mathbb{P}\{X_1=x_1\}\mathbb{P}\{S_1=s_1|X_1=x_1\}\prod_{t=2}^{n}\mathbb{P}\{X_t=x_t|X_{t-1}=x_{t-1}\}\mathbb{P}\{S_t=s_t|X_t=x_t\}
\]</div>
<p>donde tenemos que sumar sobre todos los posibles caminos que generan la secuencia.</p>
<ul class="simple">
<li><p>El número de posibilidades crece <strong>exponencialmente</strong> con <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
<li><p>Se usa <strong>programación dinámica</strong> para calcular la suma anterior de manera <strong>eficiente</strong>. El resultado es el <strong>algoritmo “forward”</strong>.</p></li>
</ul>
</section>
<section id="descodificacion">
<span id="content-markov-hmm-descodificacion"></span><h2>4.5.3 Descodificación<a class="headerlink" href="#descodificacion" title="Link to this heading">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>¡Tras la fase de aprendizaje!</p>
</div>
<p>Dada una secuencia de sı́mbolos (aminoácidos), ¿puedo calcular la secuencia de estados ocultos (estructuras secundarias) que maximiza la verosimilitud <span class="math notranslate nohighlight">\(\mathbb{P}\{\mathcal{est}, \mathcal{sim} \}\)</span>?</p>
<ul class="simple">
<li><p>Es un proceso de máxima verosimilitud.</p></li>
<li><p>Se usa <strong>programación dinámica</strong> eligiendo la rama de <strong>mayor probabilidad</strong> en cada paso de la secuencia.</p></li>
<li><p>El resultado es el <strong>algoritmo de Viterbi</strong>.</p></li>
</ul>
<section id="algoritmo-de-viterbi">
<h3>Algoritmo de Viterbi<a class="headerlink" href="#algoritmo-de-viterbi" title="Link to this heading">#</a></h3>
<p>Para el ejemplo anterior:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{v}_0=\left(\stackrel{H}{0.6},\quad 
\stackrel{C}{0.4}
\right),\quad
P=
\stackrel{H\quad C}{%
    \begin{bmatrix}
    0.6 &amp; 0.4 \\
    0.3 &amp; 0.7 
    \end{bmatrix}%
  },\quad
E=
\begin{matrix}
H \\C
\end{matrix}
\stackrel{G\quad W\quad M}{%
    \begin{bmatrix}
    0.6 &amp; 0.3 &amp; 0.1 \\
    0.2 &amp; 0.4 &amp; 0.4 
    \end{bmatrix}%
  }
\end{split}\]</div>
<p>Tenemos una cadena con tres símbolos observados: <span class="math notranslate nohighlight">\(G-W-M\)</span> (en ese orden). Queremos conocer la cadena de estados subyacente <strong>más probable</strong>.</p>
<figure class="align-default" id="markdown-fig-4-05-1">
<a class="reference internal image-reference" href="_images/hmm1.png"><img alt="_images/hmm1.png" src="_images/hmm1.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi^{(0)}=\left(\stackrel{\color{red}{H}}{\color{red}{0.6}},\quad 
\stackrel{\color{blue}{C}}{\color{blue}{0.4}}
\right),\quad
P=
\stackrel{H\quad C}{%
    \begin{bmatrix}
    0.6 &amp; 0.4 \\
    0.3 &amp; 0.7 
    \end{bmatrix}%
  },\quad
E=
\begin{matrix}
H \\C
\end{matrix}
\stackrel{\color{orange}{G}\quad W\quad M}{%
    \begin{bmatrix}
    \color{red}{0.6} &amp; 0.3 &amp; 0.1 \\
    \color{blue}{0.2} &amp; 0.4 &amp; 0.4 
    \end{bmatrix}%
  }
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(H)=\pi^{(0)}(H)\cdot E(H\rightarrow G)= 0.6 \times 0.6 = 0.36
\]</div>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(C)=\pi^{(0)}(C)\cdot E(C\rightarrow G)= 0.4 \times 0.2 = 0.08
\]</div>
<figure class="align-default" id="markdown-fig-4-05-2">
<a class="reference internal image-reference" href="_images/hmm2.png"><img alt="_images/hmm2.png" src="_images/hmm2.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Siguiente paso: calculamos las probabilidades de las 4 cadenas posibles.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Importante</strong></p>
<p>Partimos de</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathcal{L}_1=\left(
\stackrel{\color{red}{H}}{\color{red}{0.36}}
,\quad 
\stackrel{\color{blue}{C}}{\color{blue}{0.08}}
\right)
,\quad
P=
\stackrel{H\quad C}{%
    \begin{bmatrix}
    0.6 &amp; 0.4 \\
    0.3 &amp; 0.7 
    \end{bmatrix}%
  },\quad
E=
\begin{matrix}
H \\C
\end{matrix}
\stackrel{G\quad \color{orange}{W}\quad M}{%
    \begin{bmatrix}
    0.6 &amp; 0.3 &amp; 0.1 \\
    0.2 &amp; 0.4 &amp; 0.4 
    \end{bmatrix}%
  }
\end{split}\]</div>
</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-H\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(H)\cdot P(H\rightarrow H)\cdot E(H\rightarrow W) = 0.36 \times 0.6 \times 0.3 = 0.0648
\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(C-H\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(C)\cdot P(C\rightarrow H)\cdot E(H\rightarrow W) = 0.08 \times 0.3 \times 0.3 = 0.0072
\]</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Importante</strong></p>
<p>En este momento podemos rechazar la cadena <span class="math notranslate nohighlight">\(C-H\)</span> frente a <span class="math notranslate nohighlight">\(H-H\)</span>, ya que la primera tiene menos probabilidad de ocurrir. Aquí radica la potencia del algoritmo de Viterbi: dejamos de calcular las probabilidades de todas las cadenas sucesivas a <span class="math notranslate nohighlight">\(C-H\)</span>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Esta selección se hace a <strong>nivel de nodo</strong>: rechazamos uno de los caminos que <strong>llegan a un nodo</strong>.</p>
</div>
<figure class="align-default" id="markdown-fig-4-05-3">
<a class="reference internal image-reference" href="_images/hmm3.png"><img alt="_images/hmm3.png" src="_images/hmm3.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-C\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(H)\cdot P(H\rightarrow C)\cdot E(C\rightarrow W) = 0.36 \times 0.4 \times 0.4 = 0.0576
\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(C-C\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_1(C)\cdot P(C\rightarrow C)\cdot E(C\rightarrow W) = 0.08 \times 0.7 \times 0.4 = 0.0224
\]</div>
<blockquote>
<div><p>Igualmente, aquí podemos descartar la cadena <span class="math notranslate nohighlight">\(C-C\)</span> frente a <span class="math notranslate nohighlight">\(H-C\)</span> (y todas las sucesivas cadenas de <span class="math notranslate nohighlight">\(C-C\)</span>).</p>
</div></blockquote>
<p>Hemos rechazado los caminos <span class="math notranslate nohighlight">\(C-C\)</span> y <span class="math notranslate nohighlight">\(C-H\)</span>, por tanto podemos rechazar que la cadena pasa por nodo <span class="math notranslate nohighlight">\(C\)</span> en la primera etapa.</p>
<blockquote>
<div><p>En cada caso: tomamos el camino de <strong>mayor probabilidad</strong> y marcamos el nodo.</p>
</div></blockquote>
<figure class="align-default" id="markdown-fig-4-05-4">
<a class="reference internal image-reference" href="_images/hmm4.png"><img alt="_images/hmm4.png" src="_images/hmm4.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-4" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="warning admonition">
<p class="admonition-title"><strong>Importante</strong></p>
<p><strong>NO</strong> podemos rechazar, no obstante, el nodo <span class="math notranslate nohighlight">\(C\)</span> en la segunda etapa de la cadena (emisión <span class="math notranslate nohighlight">\(=W\)</span>). En este momento disponemos de la probabilidad que la cadena sea <span class="math notranslate nohighlight">\(H-C\)</span> ó <span class="math notranslate nohighlight">\(H-H\)</span>, pero la cadena de Markov <strong>continua</strong>.</p>
</div>
<blockquote>
<div><p>Continuamos el proceso hasta la última etapa de la cadena: calculamos las probabilidades de las cadenas restantes, que son:</p>
</div></blockquote>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H-H-H\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(H-H-C\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(H-C-H\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(H-C-C\)</span></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>En la tercera etapa el estado observado es <span class="math notranslate nohighlight">\(M\)</span></p>
</div>
<p>Partimos de esta situación</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathcal{L}_2=\left(
\stackrel{\color{red}{H}}{\color{red}{0.065}}
,\quad 
\stackrel{\color{blue}{C}}{\color{blue}{0.0058}}
\right)
,\quad
P=
\stackrel{H\quad C}{%
    \begin{bmatrix}
    0.6 &amp; 0.4 \\
    0.3 &amp; 0.7 
    \end{bmatrix}%
  },\quad
E=
\begin{matrix}
H \\C
\end{matrix}
\stackrel{G\quad \color{orange}{W}\quad M}{%
    \begin{bmatrix}
    0.6 &amp; 0.3 &amp; 0.1 \\
    0.2 &amp; 0.4 &amp; 0.4 
    \end{bmatrix}%
  }
\end{split}\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-H-H\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_2(H)\cdot P(H\rightarrow H)\cdot E(H\rightarrow M) = 0.065\times 0.6 \times 0.1 = 0.0039
\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-H-C\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_2(H)\cdot P(H\rightarrow C)\cdot E(C\rightarrow M) = 0.065\times 0.4 \times 0.4 = 0.0104
\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-C-H\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_2(C)\cdot P(C\rightarrow H)\cdot E(H\rightarrow M) = 0.058 \times 0.3 \times 0.1 = 0.00174
\]</div>
<ul class="simple">
<li><p>Probabilidad de la cadena <span class="math notranslate nohighlight">\(H-C-C\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_2(C)\cdot P(C\rightarrow C)\cdot E(C\rightarrow M) = 0.058\times 0.7\times 0.4 = 0.01624
\]</div>
<figure class="align-default" id="markdown-fig-4-05-5">
<a class="reference internal image-reference" href="_images/hmm5.png"><img alt="_images/hmm5.png" src="_images/hmm5.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<blockquote>
<div><p>Observaciones</p>
</div></blockquote>
<ul class="simple">
<li><p>De los dos caminos que llegan a <span class="math notranslate nohighlight">\(H\)</span> en la tercera etapa, el más probable es el que viene de <span class="math notranslate nohighlight">\(C\)</span>, por tanto descartamos el camino <span class="math notranslate nohighlight">\(H-H-H\)</span>.</p></li>
<li><p>De los dos caminos que llegan a <span class="math notranslate nohighlight">\(C\)</span> en la tercera etapa, el más probable es el que proviene de <span class="math notranslate nohighlight">\(C\)</span> en la segunda. Descartamos el camino <span class="math notranslate nohighlight">\(H-H-C\)</span>.</p></li>
<li><p>Las dos observaciones anteriores hacen que descartemos el estado <span class="math notranslate nohighlight">\(H\)</span> en la segunda etapa. Esto no es trivial, pues si hubiésemos detenido el proceso en dicha etapa, el último estado más probable hubiera sido <span class="math notranslate nohighlight">\(H\)</span>!</p></li>
<li><p>Los dos posibles caminos son</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(H-C-H\)</span> con una probabilidad de 0.001728</p></li>
<li><p><span class="math notranslate nohighlight">\(H-C-C\)</span> con una probabilidad de 0.0161</p></li>
</ul>
</li>
</ul>
<p>El último estado es el de mayor verosimilitud: <span class="math notranslate nohighlight">\(H-C-C\)</span>.</p>
<figure class="align-default" id="markdown-fig-4-05-6">
<a class="reference internal image-reference" href="_images/hmm6.png"><img alt="_images/hmm6.png" src="_images/hmm6.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Viterbi</span><a class="headerlink" href="#markdown-fig-4-05-6" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="04.04_ModelosMarkovOcultos.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Modelos de Markov Ocultos</p>
      </div>
    </a>
    <a class="right-next"
       href="04.06_CadenasMarkov.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Práctica 1: cadenas de Markov como Modelos de Secuencias</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje">4.5.1 Aprendizaje</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-1-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">Caso 1: conocemos las secuencias de estados asociadas a los símbolos</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-2-no-conocemos-las-secuencias-de-estados-asociadas-a-los-simbolos">Caso 2: no conocemos las secuencias de estados asociadas a los símbolos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion">4.5.2 Evaluación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#descodificacion">4.5.3 Descodificación</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-de-viterbi">Algoritmo de Viterbi</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Departamento de Matemática Aplicada
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio sobre variedades vínicolas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se va a utilizar un archivo con información de variedades vinícolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preparan las columnas a tratar\n",
    "import pandas as pd\n",
    "df_wine = pd.read_csv('data/wine.csv', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol',\n",
    "    'Malic acid', 'Ash',\n",
    "    'Alcalinity of ash',\n",
    "    'Magnesium', 'Total phenols',\n",
    "    'Flavanoids', 'Nonflavanoid phenols',\n",
    "    'Proanthocyanins',\n",
    "    'Color intensity', 'Hue',\n",
    "    'OD280/OD315 of diluted wines'\n",
    "    ,'Proline']\n",
    "# Se borra la clase 1\n",
    "df_wine = df_wine[df_wine['Class label'] != 1]\n",
    "df_wine.head()\n",
    "# Se toma el campo 'Class label' como variable objetivo y\n",
    "# Se toman los campos 'Alcohol' y 'OD280/OD315 of diluted wines' como características sobre una matriz X\n",
    "y = df_wine['Class label'].values\n",
    "X = df_wine[['Alcohol', 'OD280/OD315 of diluted wines']].values\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentar una vista del dataframe cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproceso de datos\n",
    "\n",
    "__NOTA A sklearn.metrics__:__ Algunas métricas se definen esencialmente para tareas de clasificación binaria (por ejemplo, f1_score, roc_auc_score). En estos casos, por defecto solo se evalúa la etiqueta positiva, asumiendo por defecto que la clase positiva está etiquetada como 1 (aunque esto puede configurarse a través del __parámetro pos_label__).\n",
    "\n",
    "Por lo tanto hay dos alternativas:\n",
    "\n",
    "- __Se recodifica la variable objetivo y__, que contiene la etiqueta 'Class label' para que adopte los valores (0,1)\n",
    "- __Este ejemplo se convierte en una clasificación binaria__, y se pueden mostrar sus métricas con sklearn.metrics\n",
    "\n",
    "La otra posibilidad es:\n",
    "- __No alterar los valores de y__\n",
    "- Indicar en las llamadas a __sklearn.metrics__ en __pos_label__ la etiqueta que funciona como verdadero (3 por ejemplo).\n",
    "\n",
    "__Y finalmente se trocea el conjunto de entrada en entrenamiento 80% y prueba 20%__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "#y = le.fit_transform(y)\n",
    "print(np.unique(y))\n",
    "# Troceamos las caracteristicas de X en un 80% de entrenamiento y un 20% de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacer un entrenamiento con la clase GaussianNB que implementa naive-Bayes en sk-learn\n",
    "\n",
    "- Entrenar el modelo con X_train, y_train\n",
    "- Validar con X_test, y_test utilizando la librería sklearn.metrics. Al ser una clasificación binario se pueden obtener métricas tal como exactitud, precisión y sensibilidad\n",
    "- Se puede verificar que la exactitud coincide con el recuento de aciertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.917\n",
      "Precision: 0.833\n",
      "Sensibilidad - Recall: 1.000\n",
      "F1: 0.909\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del clasificador (porcentaje de aciertos) = 91.66666666666667 \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestra la correspondiente matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetir el entrenamiento con la clase  DecissionTreeClassifier que implementa el árbol de decisión en sk-learn\n",
    "\n",
    "- Entrenar el modelo con X_train, y_train\n",
    "- Validar con X_test, y_test utilizando la librería sklearn.metrics. \n",
    "- Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud - Accuracy: 0.833\n",
      "Precision: 0.800\n",
      "Sensibilidad - Recall: 0.800\n",
      "F1: 0.800\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De forma volutaria, se puede buscar la documentación de la clase RandomForestClassifier\n",
    "\n",
    "__Esta clase está implementada en la librería sklearn.ensemble__\n",
    "\n",
    "__RamdomForest implementa internamente varios árboles de decisión que se ensamblan y se toma como resultado para la clasificación el voto mayoritario__\n",
    "\n",
    "__Parámetros principales del constructor__:\n",
    "\n",
    "- __n_estimators__ : número de árboles, 100 por defecto\n",
    "- __criterion__ : criterio de partición ('gini', 'entropy'), por defecto es 'gini'.\n",
    "\n",
    "Para más información:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De forma voluntaria también se puede aplicar la implementación del Bagging\n",
    "\n",
    "Se realizarán 100 repeticiones utilizando árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ahora se hace uso de N clasificadores entrenados para predecir con voto mayoritario el conjunto de test__ \n",
    "\n",
    "__Se usa la moda como forma de obtener la etiqueta más votada__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
